# 추가 질문 및 구체적 개발 계획

## 🔍 추가 확인이 필요한 사항

### 1. 작업 상태 관리 방식
- **질문**: 작업 상태를 DB에 저장할지, 아니면 in-memory dict로 관리할지?
- **제안**: 
  - DB 저장 권장 (서버 재시작 시에도 상태 유지, 확장성)
  - SQLModel로 `Task` 테이블 생성
  - 상태: `pending`, `processing`, `completed`, `failed`
- **기본 결정**: DB 저장으로 진행 (참고 프로젝트 구조 따름)
A. DB 저장으로 하기.

### 2. 파일 저장 경로 구조
- **제안 구조**:
  ```
  /data/ephemeral/home/jsw/pro-cv-finalproject-cv-11/app/
  ├── storage/
  │   ├── videos/          # 업로드된 원본 영상
  │   ├── clips/         # 이벤트 구간 영상 클립
  │   ├── images/          # 추출된 이미지들
  │   │   ├── key_frames/     # 핵심 프레임
  │   │   ├── vehicle_crops/  # 차량 crop
  │   │   └── license_crops/  # 번호판 crop
  │   └── temp/           # 임시 파일
  ```
- **GCP 마이그레이션 준비**: `storage/` 디렉토리 관련 코드에 `# TODO: GCP migration` 주석 추가
A. 좋아.

### 3. 이벤트 ID 생성 방식
- **질문**: `event_id`를 어떻게 생성할지? (UUID, 순차적 숫자, 타임스탬프 기반?)
- **제안**: UUID 사용 (고유성 보장, 분산 환경 대응)
A. 좋아.

### 4. 영상 메타데이터 추출 라이브러리
- **질문**: 영상 메타데이터(FPS, 촬영 시간 등) 추출에 어떤 라이브러리 사용할지?
- **제안**: `opencv-python` (cv2) 또는 `ffmpeg-python` 사용
- **기본 결정**: `opencv-python` 사용 (가벼움, 범용성)
A. 좋아.

### 5. 이미지 저장 형식
- **질문**: 이미지들을 파일로 저장할지, Base64로 인코딩해서 DB에 저장할지?
- **제안**: 
  - 파일로 저장 (성능, DB 부하 감소)
  - DB에는 파일 경로만 저장
  - API 응답 시 필요시 Base64로 변환하여 반환
A. 좋아.

### 6. API 엔드포인트 네이밍
- **질문**: `/api/v1/` prefix 사용할지?
- **제안**: 참고 프로젝트와 일관성 유지, `/api/v1/` 사용
A. 너가 적절히 판단해서 해줘.

### 7. LLM 선택지
- **질문**: 어떤 LLM들을 선택지로 제공할지?
- **제안**: 
  - OpenAI (GPT-3.5, GPT-4)
  - Anthropic (Claude)
  - Google (Gemini)
  - 선택지: "사용 안 함", "OpenAI", "Anthropic", "Google" 등
- **기본 결정**: 일단 스키마에만 포함, 실제 구현은 나중에
A. 좋아. 일단 저 3개 스키마 제공하는 것도 좋아.

## 📋 구체적 개발 계획

### Phase 1: 프로젝트 구조 및 기본 설정 (우선순위: 최상)

#### 1.1 디렉토리 구조 생성
```
app/
├── main.py              # FastAPI 앱 진입점
├── config.py            # 설정 관리
├── database.py          # DB 연결 및 모델
├── dependencies.py      # 의존성 (모델 로드 등)
├── schemas.py           # Pydantic 스키마
├── api.py               # API 라우터
├── services/            # 비즈니스 로직
│   ├── __init__.py
│   ├── video_service.py      # 영상 처리 서비스
│   ├── event_service.py      # 이벤트 검출 서비스
│   ├── image_service.py      # 이미지 처리 서비스
│   └── llm_service.py        # LLM 서비스 (나중에)
├── storage/             # 파일 저장소
│   ├── videos/
│   ├── clips/
│   └── images/
└── utils/               # 유틸리티
    ├── __init__.py
    ├── video_utils.py        # 영상 메타데이터 추출
    └── file_utils.py         # 파일 관리
```

#### 1.2 기본 설정 파일 구현
- `config.py`: 환경 변수 기반 설정
  - DB URL
  - 모델 경로
  - 스토리지 경로
  - API 설정

#### 1.3 의존성 파일 구현
- `dependencies.py`: 
  - 모델 로드 함수 (향후 실제 모델 통합 대비)
  - 현재는 Dummy 모델 인터페이스만

### Phase 2: 데이터베이스 및 스키마 (우선순위: 최상)

#### 2.1 데이터베이스 모델 (SQLModel)
```python
# database.py
- Task: 작업 상태 관리
  - id (UUID, PK)
  - status (pending/processing/completed/failed)
  - progress (0-100)
  - current_step (문자열)
  - video_path (문자열)
  - user_info (JSON)
  - created_at, updated_at
  - error_message (nullable)

- Event: 검출된 이벤트
  - id (UUID, PK)
  - task_id (FK)
  - event_type (문자열)
  - violation_type (문자열)
  - timestamp (문자열)
  - risk_level (문자열)
  - vehicle_number (문자열)
  - location (문자열, nullable)
  - date, time (문자열)
  - title, content (문자열)
  - video_clip_path (문자열, nullable)
  - key_frame_path (문자열, nullable)
  - vehicle_crop_path (문자열, nullable)
  - license_crop_path (문자열, nullable)
  - created_at
```

#### 2.2 Pydantic 스키마
```python
# schemas.py
- UploadRequest: 영상 업로드 요청
- UploadResponse: 작업 ID 반환
- TaskStatusResponse: 작업 상태 조회
- TaskResultsResponse: 분석 결과 조회
- EventResponse: 이벤트 정보
- UserInfo: 사용자 정보
- LLMRequest: LLM 생성 요청 (나중에)
```

### Phase 3: FastAPI 서버 구현 (우선순위: 최상)

#### 3.1 메인 앱 설정
- `main.py`: FastAPI 앱 초기화
- Lifespan 이벤트로 DB 테이블 생성, 모델 로드

#### 3.2 API 라우터 구현
- `GET /health`: 서버 상태 확인
- `POST /api/v1/upload`: 영상 업로드
  - 파일 저장
  - Task 생성 (status: pending)
  - Background Task 시작
  - task_id 반환 (202 Accepted)
- `GET /api/v1/tasks/{task_id}/status`: 작업 상태 조회
- `GET /api/v1/tasks/{task_id}/results`: 분석 결과 조회

#### 3.3 Background Task 구현
- 영상 분석 작업을 백그라운드에서 실행
- 진행률 업데이트 (DB에 저장)
- 에러 발생 시 상태를 failed로 변경

### Phase 4: Dummy 이벤트 검출 로직 (우선순위: 높음)

#### 4.1 영상 메타데이터 추출
- `utils/video_utils.py`:
  - FPS 추출
  - 촬영 시간 추출 (EXIF 또는 파일 메타데이터)
  - 영상 길이 추출

#### 4.2 Dummy 이벤트 생성
- `services/event_service.py`:
  - `dummy_events.json` 구조 참고
  - 4가지 이벤트 타입 중 랜덤 선택
  - 발생 시각 계산 (영상 메타데이터 기반)
  - 더미 차량 번호 생성

#### 4.3 이벤트 검출 시뮬레이션
- 영상 길이에 따라 1-5개 이벤트 생성
- 각 이벤트마다 타임스탬프 랜덤 할당

### Phase 5: 이미지/영상 처리 (Dummy) (우선순위: 높음)

#### 5.1 핵심 프레임 추출
- `services/image_service.py`:
  - 이벤트 타임스탬프에 해당하는 프레임 추출
  - 더미 이미지 생성 또는 실제 프레임 추출

#### 5.2 차량/번호판 Crop
- 더미 bounding box로 crop
- 실제 모델 통합 시 인터페이스만 유지

#### 5.3 번호판 OCR (Dummy)
- 더미 번호 반환 (예: "12가3456")

#### 5.4 영상 클립 생성
- 이벤트 구간 영상 클립 생성 (Dummy 또는 실제)

### Phase 6: Streamlit UI 구현 (우선순위: 높음)

#### 6.1 기본 레이아웃
- `frontend/ui.py` 수정 (기존 `ui_tmp.py` 참고)
- 단일 페이지 구조
- 사이드바: LLM 옵션

#### 6.2 영상 업로드 섹션
- 파일 업로더
- 업로드 상태 표시

#### 6.3 사용자 정보 입력
- 휴대전화
- 신고 내용 공유 (기본: 아니요)
- 인적 사항 (선택)

#### 6.4 분석 결과 표시
- 검출 결과 요약 (통계)
- 아코디언으로 각 이벤트 표시
- 탭 구조: 기본 정보, 영상/사진, 신고 양식, 내보내기

#### 6.5 신고 양식 기능
- 12가지 항목 자동 포맷팅
- 제목/내용 수정 가능
- 인증번호 입력
- JSON/CSV 다운로드

### Phase 7: 통합 및 테스트 (우선순위: 중간)

#### 7.1 통합 테스트
- 전체 플로우 테스트
- 에러 케이스 테스트

#### 7.2 로깅 및 에러 처리
- loguru로 주요 이벤트 로깅
- 적절한 에러 메시지 반환

## 🚀 개발 순서 (우선순위 기반)

1. **Phase 1**: 프로젝트 구조 및 기본 설정
2. **Phase 2**: 데이터베이스 및 스키마
3. **Phase 3**: FastAPI 서버 구현 (기본 구조)
4. **Phase 4**: Dummy 이벤트 검출 로직
5. **Phase 5**: 이미지/영상 처리 (Dummy)
6. **Phase 6**: Streamlit UI 구현
7. **Phase 7**: 통합 및 테스트

## 📝 개발 시 주의사항

1. **GCP 마이그레이션 준비**
   - 파일 저장 관련 코드에 `# TODO: GCP migration` 주석
   - 스토리지 경로를 config로 관리

2. **모델 통합 대비**
   - 모델 로드 인터페이스 설계
   - Dummy 함수와 실제 함수 교체 가능하도록 구조화

3. **GPS 정보**
   - 스키마에 포함하되, 현재는 null 또는 기본값 반환
   - 추후 구현 시 주석으로 표시

4. **LLM 선택지**
   - UI에 선택지 제공
   - 스키마에 LLM 타입 필드 포함
   - 실제 구현은 나중에

5. **에러 처리**
   - 적절한 HTTP 상태 코드 반환
   - 사용자 친화적 에러 메시지

6. **로깅**
   - 주요 작업 단계 로깅
   - 에러 발생 시 상세 로그

## ❓ 최종 확인 질문

1. **작업 상태 관리**: DB 저장으로 진행해도 될까요?
2. **파일 저장 경로**: 제안한 구조로 진행해도 될까요?
3. **이벤트 ID**: UUID 사용해도 될까요?
4. **영상 메타데이터**: opencv-python 사용해도 될까요?
5. **이미지 저장**: 파일로 저장하고 경로만 DB에 저장해도 될까요?
6. **LLM 선택지**: 어떤 LLM들을 선택지로 제공할까요? (일단 스키마만 만들어도 될까요?)

위 질문들에 대한 답변이 없어도 기본 제안대로 진행 가능합니다. 개발을 시작할까요?

# 추가로 제공하고 싶은 정보
1. 일단 입력 비디오는 저런 식으로 주어지는데, 제목에 저렇게 날짜랑 시간이 나온다고 일단 가정할 것. 
정확히는 나중에 대규모 dataset으로 학습시키고 추론 테스트할 건데 거기는 제목이 0001.avi 이런 식일 확률이 높음.
다만 우리가 최종 배포할 때는 실제 블랙박스 영상을 추출할 것이기에 저런 식으로 날짜랑 시간이 포함될 확률이 높기 때문임.

2. 일단 그러면 더미 번호판은 /data/ephemeral/home/jsw/pro-cv-finalproject-cv-11/storage/dummy_plate_images꺼 일단 쓰는 거 어때? 나중에 모델이 추론한 거 쓰도록 코드 바꾸면 되니까.

3. 일단 입력 이미지에 대해, 지금은 모델이 없으니까, 대충 1초~5초, 6초~10초, 11초~15초 구간이 위반 events라고 가정하고, 그 구간을 clip하는 걸로 하는 건 어때? 이것도 나중에 모델이 지정한 clip 구간으로 하면 되니까. 중요 프레임도 저 구간에서 뽑고. 일단 start랑 end의 사이(ex. 1초랑 5초면 (1+5)/2 = 3초)에서 프레임 뽑으면 되겠다.

4. 번호판은 일단 plate1은 154러 7070, plate2는 157고 4895, plate3은 120서 6041이야. 우리 지금 번호판 ocr 모델이 아직 없으니까, 이 숫자로 하드코딩해줘.