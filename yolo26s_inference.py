#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOv26s Vehicle Detection - Inference
- Fine-tuned vehicle detection ëª¨ë¸ë¡œ ì¶”ë¡  ìˆ˜í–‰
- ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì„ íƒ í›„ ì¶”ë¡ 
"""

import os
import re
from pathlib import Path
from collections import defaultdict
from ultralytics import YOLO


# ========== ì„¤ì • ë³€ìˆ˜ ==========
# ëª¨ë¸ ì„¤ì •
MODEL_WEIGHT = "runs/detect/cv-11-final/yolo26s_v4-2_e1_b64/weights/best.pt"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ

# ë°ì´í„° ê²½ë¡œ
IMAGE_DIR = "/data/ephemeral/home/dataset/flatten_road_dataset_bb/val/images"

# ì¶”ë¡  ì„¤ì •
CONF_THRESHOLD = 0.25
IOU_THRESHOLD = 0.45

# ì €ì¥ ê²½ë¡œ
VERSION = "v4-2"
INFERENCE_PROJECT = "inference"
INFERENCE_NAME_PREFIX = f"yolo26s_{VERSION}"

# ì‹œí€€ìŠ¤ ì„ íƒ (Noneì´ë©´ ëŒ€í™”í˜•ìœ¼ë¡œ ì„ íƒ)
SELECTED_SEQUENCE = None  # ì˜ˆ: "20201019_161210" ë˜ëŠ” None
# ================================


def find_sequences(image_dir):
    """
    ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ì—ì„œ ì‹œí€€ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
    
    Args:
        image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        dict: {timestamp: [image_paths]}
    """
    image_dir = Path(image_dir)
    
    if not image_dir.exists():
        print(f"[Error] ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_dir}")
        return {}
    
    # ëª¨ë“  jpg íŒŒì¼ ì°¾ê¸°
    images = sorted(image_dir.glob("*.jpg"))
    
    if not images:
        print(f"[Error] ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        return {}
    
    # ì‹œí€€ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
    sequences = defaultdict(list)
    pattern = re.compile(r'.*_(\d{8}_\d{6})_\d+\.jpg')
    
    for img in images:
        match = pattern.match(img.name)
        if match:
            timestamp = match.group(1)
            sequences[timestamp].append(str(img))
    
    return dict(sequences)


def display_sequences(sequences):
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤ ëª©ë¡ ì¶œë ¥
    
    Args:
        sequences: ì‹œí€€ìŠ¤ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "=" * 70)
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤")
    print("=" * 70)
    
    sorted_keys = sorted(sequences.keys())
    
    for i, timestamp in enumerate(sorted_keys, 1):
        date = timestamp[:8]  # YYYYMMDD
        time = timestamp[9:]   # HHMMSS
        frame_count = len(sequences[timestamp])
        
        # ë‚ ì§œì™€ ì‹œê°„ í¬ë§·íŒ…
        formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:8]}"
        formatted_time = f"{time[:2]}:{time[2:4]}:{time[4:6]}"
        
        print(f"  [{i:2d}] {timestamp}")
        print(f"       ë‚ ì§œ: {formatted_date}, ì‹œê°„: {formatted_time}")
        print(f"       í”„ë ˆì„ ìˆ˜: {frame_count}ê°œ")
        print()
    
    print("=" * 70)
    return sorted_keys


def select_sequence(sequences):
    """
    ì‚¬ìš©ìì—ê²Œ ì‹œí€€ìŠ¤ ì„ íƒ ìš”ì²­
    
    Args:
        sequences: ì‹œí€€ìŠ¤ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (timestamp, image_paths)
    """
    sorted_keys = display_sequences(sequences)
    
    while True:
        try:
            choice = input(f"\nì¶”ë¡ í•  ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{len(sorted_keys)}): ")
            idx = int(choice) - 1
            
            if 0 <= idx < len(sorted_keys):
                selected_timestamp = sorted_keys[idx]
                print(f"\nâœ“ ì„ íƒëœ ì‹œí€€ìŠ¤: {selected_timestamp}")
                return selected_timestamp, sequences[selected_timestamp]
            else:
                print(f"[Error] 1ì—ì„œ {len(sorted_keys)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("[Error] ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except KeyboardInterrupt:
            print("\n\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit(0)


def run_inference(model, images, sequence_name):
    """
    ì„ íƒí•œ ì‹œí€€ìŠ¤ë¡œ ì¶”ë¡  ìˆ˜í–‰
    
    Args:
        model: YOLO ëª¨ë¸
        images: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        sequence_name: ì‹œí€€ìŠ¤ ì´ë¦„ (timestamp)
    """
    print("\n" + "=" * 70)
    print(f"ì¶”ë¡  ì‹œì‘: {sequence_name}")
    print("=" * 70)
    print(f"í”„ë ˆì„ ìˆ˜: {len(images)}")
    print(f"Confidence threshold: {CONF_THRESHOLD}")
    print(f"IoU threshold: {IOU_THRESHOLD}")
    print()
    
    # ì €ì¥ ê²½ë¡œ êµ¬ì„±: inference/yolo26s_{VERSION}/{seq_name}
    project_path = f"{INFERENCE_PROJECT}/{INFERENCE_NAME_PREFIX}"
    
    # ì¶”ë¡  ìˆ˜í–‰
    results = model.predict(
        source=images,
        conf=CONF_THRESHOLD,
        iou=IOU_THRESHOLD,
        save=True,  # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        save_txt=True,  # ê²°ê³¼ í…ìŠ¤íŠ¸ ì €ì¥
        project=project_path,
        name=sequence_name,
        exist_ok=True,
        stream=True,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
    )
    
    # ê²°ê³¼ ì²˜ë¦¬ ë° í†µê³„
    frame_count = 0
    total_detections = 0
    detections_per_frame = []
    
    for result in results:
        frame_count += 1
        num_boxes = len(result.boxes)
        total_detections += num_boxes
        detections_per_frame.append(num_boxes)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥ (100 í”„ë ˆì„ë§ˆë‹¤)
        if frame_count % 100 == 0:
            print(f"  ì²˜ë¦¬ ì¤‘... {frame_count}/{len(images)} í”„ë ˆì„")
    
    # í†µê³„ ê³„ì‚°
    avg_detections = total_detections / frame_count if frame_count > 0 else 0
    max_detections = max(detections_per_frame) if detections_per_frame else 0
    min_detections = min(detections_per_frame) if detections_per_frame else 0
    
    print()
    print("=" * 70)
    print("ì¶”ë¡  ì™„ë£Œ!")
    print("=" * 70)
    print(f"ì´ ì²˜ë¦¬ í”„ë ˆì„: {frame_count}")
    print(f"ì´ ê²€ì¶œëœ vehicle ìˆ˜: {total_detections}")
    print(f"í”„ë ˆì„ë‹¹ í‰ê·  ê²€ì¶œ ìˆ˜: {avg_detections:.2f}")
    print(f"ìµœëŒ€ ê²€ì¶œ ìˆ˜ (1 í”„ë ˆì„): {max_detections}")
    print(f"ìµœì†Œ ê²€ì¶œ ìˆ˜ (1 í”„ë ˆì„): {min_detections}")
    print()
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
    print(f"   - ì´ë¯¸ì§€: {INFERENCE_PROJECT}/{INFERENCE_NAME_PREFIX}/{sequence_name}/")
    print(f"   - í…ìŠ¤íŠ¸: {INFERENCE_PROJECT}/{INFERENCE_NAME_PREFIX}/{sequence_name}/labels/")
    print("=" * 70)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("YOLOv26s Vehicle Detection - Inference")
    print("=" * 70)
    print()
    
    # Step 1: ëª¨ë¸ ë¡œë“œ
    print("[Step 1] Fine-tuned ëª¨ë¸ ë¡œë“œ")
    print("-" * 70)
    print(f"ëª¨ë¸: {MODEL_WEIGHT}")
    
    if not os.path.exists(MODEL_WEIGHT):
        print(f"[Error] ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_WEIGHT}")
        print("ë¨¼ì € yolo26s_train.pyë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return
    
    model = YOLO(MODEL_WEIGHT)
    print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print()
    
    # Step 2: ì‹œí€€ìŠ¤ ì°¾ê¸°
    print("[Step 2] ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ íƒìƒ‰")
    print("-" * 70)
    
    sequences = find_sequences(IMAGE_DIR)
    
    if not sequences:
        print("[Error] ì‹œí€€ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ“ {len(sequences)}ê°œì˜ ì‹œí€€ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # Step 3: ì‹œí€€ìŠ¤ ì„ íƒ
    print("\n[Step 3] ì‹œí€€ìŠ¤ ì„ íƒ")
    print("-" * 70)
    
    if SELECTED_SEQUENCE:
        # ì„¤ì • ë³€ìˆ˜ë¡œ ì§€ì •ëœ ì‹œí€€ìŠ¤ ì‚¬ìš©
        if SELECTED_SEQUENCE in sequences:
            timestamp = SELECTED_SEQUENCE
            images = sequences[timestamp]
            print(f"âœ“ ì‚¬ì „ ì„ íƒëœ ì‹œí€€ìŠ¤: {timestamp} ({len(images)} í”„ë ˆì„)")
        else:
            print(f"[Error] ì§€ì •ëœ ì‹œí€€ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SELECTED_SEQUENCE}")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤: {list(sequences.keys())[:5]}...")
            return
    else:
        # ëŒ€í™”í˜•ìœ¼ë¡œ ì„ íƒ
        timestamp, images = select_sequence(sequences)
    
    # Step 4: ì¶”ë¡  ìˆ˜í–‰
    run_inference(model, images, timestamp)
    
    print("\nâœ“ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == '__main__':
    main()

